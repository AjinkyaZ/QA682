{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable as var\n",
    "from torch.nn import functional as F\n",
    "import torchtext.vocab as vocab\n",
    "import torch.autograd as autograd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import json\n",
    "import _pickle as pkl\n",
    "# from helpers.utils import StandardNLL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [04:31, 3.18MB/s]                               \n",
      "100%|██████████| 400000/400000 [00:05<00:00, 68116.00it/s]\n"
     ]
    }
   ],
   "source": [
    "glove = vocab.GloVe(name='6B', dim=50)\n",
    "# MAX_QUES_LEN = 92\n",
    "# MAX_CONTEXT_LEN= 921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The clergy was divided into two types: the secular clergy, who lived out in the world, and the regular clergy, who lived under a religious rule and were usually monks. Throughout the period monks remained a very small proportion of the population, usually less than one per cent. Most of the regular clergy were drawn from the nobility, the same social class that served as the recruiting ground for the upper levels of the secular clergy. The local parish priests were often drawn from the peasant class. Townsmen were in a somewhat unusual position, as they did not fit into the traditional three-fold division of society into nobles, clergy, and peasants. During the 12th and 13th centuries, the ranks of the townsmen expanded greatly as existing towns grew and new population centres were founded. But throughout the Middle Ages the population of the towns probably never exceeded 10 per cent of the total population.',\n",
       "  'What percentage of the European population consisted of monks?',\n",
       "  'less than one per cent'],\n",
       " [\"Since the late 18th century, Paris has been famous for its restaurants and haute cuisine, food meticulously prepared and artfully presented. A luxury restaurant, La Taverne Anglaise, opened in 1786 in the arcades of the Palais-Royal by Antoine Beauvilliers; it featured an elegant dining room, an extensive menu, linen tablecloths, a large wine list and well-trained waiters; it became a model for future Paris restaurants. The restaurant Le Grand Véfour in the Palais-Royal dates from the same period. The famous Paris restaurants of the 19th century, including the Café de Paris, the Rocher de Cancale, the Café Anglais, Maison Dorée and the Café Riche, were mostly located near the theatres on the Boulevard des Italiens; they were immortalised in the novels of Balzac and Émile Zola. Several of the best-known restaurants in Paris today appeared during the Belle Epoque, including Maxim's on Rue Royale, Ledoyen in the gardens of the Champs-Élysées, and the Tour d'Argent on the Quai de la Tournelle.\",\n",
       "  'Near what were most restaurants opened?',\n",
       "  'theatres']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['X_train'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400000, 50])\n"
     ]
    }
   ],
   "source": [
    "print(glove.vectors.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "921\n"
     ]
    }
   ],
   "source": [
    "MAX_CONTEXT_LEN = 0\n",
    "MAX_QUES_LEN = 0\n",
    "# print(data['X_train'][0])\n",
    "for (c,q, _) in data['X_train'][:8000]:\n",
    "#     print(len(c.split()))\n",
    "    if len(c.split())> MAX_CONTEXT_LEN:\n",
    "        MAX_CONTEXT_LEN= len(c)\n",
    "    if len(q.split())> MAX_QUES_LEN:\n",
    "        MAX_QUES_LEN= len(q)\n",
    "print(MAX_QUES_LEN)\n",
    "print(MAX_CONTEXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400002, 50])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean(token):\n",
    "    cleaned_token = token.strip(\".,?!-:;'()[]\\\"`\")\n",
    "    if cleaned_token[-2:] == \"'s\":\n",
    "        cleaned_token = cleaned_token[:-2]\n",
    "    if cleaned_token[-2:] == \"'t\":\n",
    "        cleaned_token = cleaned_token[:-2]+'t'\n",
    "    return cleaned_token\n",
    "\n",
    "def vectorize(input_txt, max_len):\n",
    "    input_seq = [clean(w) for w in input_txt.split(\" \") if len(clean(w).strip())]\n",
    "    glove_vec = []\n",
    "    for w in input_seq:\n",
    "        try:\n",
    "            glove_vec.append(glove.stoi[w])\n",
    "        except:\n",
    "            glove_vec.append(400001) # <unk> token\n",
    "    if len(glove_vec)<max_len:\n",
    "        padding_zeros = [400000]*(max_len-len(glove_vec)) # <pad> token\n",
    "        glove_vec = padding_zeros + glove_vec\n",
    "    return glove_vec[:max_len]\n",
    "    \n",
    "def make_data(raw_X):\n",
    "    X = []\n",
    "    y = []\n",
    "    for (c, q, a) in raw_X:\n",
    "        context_rep = vectorize(c.lower(), MAX_CONTEXT_LEN)\n",
    "        ques_rep = vectorize(q.lower(), MAX_QUES_LEN)\n",
    "        X.append(context_rep+ques_rep) #only context for now\n",
    "    return X\n",
    "\n",
    "DIM=50\n",
    "glove = vocab.GloVe(name='6B', dim=DIM)\n",
    "\n",
    "glove.stoi['<pad>'] = len(glove.stoi)+1\n",
    "glove.vectors = torch.cat((glove.vectors, torch.zeros(1, DIM)))\n",
    "glove.stoi['<unk>'] = len(glove.stoi)+1 # add token->index for unknown/oov\n",
    "glove.vectors = torch.cat((glove.vectors, torch.ones(1, DIM)*-1)) # add index->vec for unknown/oov\n",
    "\n",
    "print(glove.vectors.size())\n",
    "VOCAB_SIZE = glove.vectors.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The boreholes on Funafuti, at the site now called Darwin's Drill, are the result of drilling conducted by the Royal Society of London for the purpose of investigating the formation of coral reefs to determine whether traces of shallow water organisms could be found at depth in the coral of Pacific atolls. This investigation followed the work on The Structure and Distribution of Coral Reefs conducted by Charles Darwin in the Pacific. Drilling occurred in 1896, 1897 and 1898. Professor Edgeworth David of the University of Sydney was a member of the 1896 \"Funafuti Coral Reef Boring Expedition of the Royal Society\", under Professor William Sollas and lead the expedition in 1897. Photographers on these trips recorded people, communities, and scenes at Funafuti.\n",
      "Question: What was Darwin's work on coral reefs titled?\n",
      "Answer Span: [347, 392]\n",
      "Answer: The Structure and Distribution of Coral Reefs\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "example_X = (data['X_train'][idx])\n",
    "example_y = (data['y_train'][idx])\n",
    "print(\"Context:\", example_X[0])\n",
    "print(\"Question:\", example_X[1])\n",
    "print(\"Answer Span:\", example_y)\n",
    "print(\"Answer:\", example_X[0][example_y[0]:example_y[1]])\n",
    "X = vectorize(example_X[0].lower(), MAX_CONTEXT_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_start = []\n",
    "y_end = []\n",
    "\n",
    "for (c,q,ans) in data['X_train']:\n",
    "#     temp_s = list(0 for i in range(MAX_CONTEXT_LEN))\n",
    "#     temp_e = list(0 for i in range(MAX_CONTEXT_LEN))\n",
    "    temp_c = c.split()\n",
    "    temp_c = ['PAD']*(MAX_CONTEXT_LEN-len(temp_c))+temp_c\n",
    "    con_new = ' '.join(temp_c)\n",
    "    start_pos = len(con_new[:con_new.find(ans)].split())-1\n",
    "    end_pos = start_pos+(len(ans.split()))-2\n",
    "#     if(start_pos)==921 or (end_pos)==921:\n",
    "#         print(c,ans)\n",
    "#         print(start_pos)\n",
    "#         print(end_pos)\n",
    "#     if(start_pos)==1:\n",
    "#         print(c,ans)\n",
    "#         print(start_pos)\n",
    "#         print(end_pos)\n",
    "#     print(temp_c)\n",
    "#     print(c)\n",
    "#     print(ans)\n",
    "#     print(start_pos, end_pos)\n",
    "#     temp_s[start_pos]=1\n",
    "#     y_start.append(temp_s)\n",
    "#     temp_e[end_pos]=1\n",
    "#     y_end.append(temp_e)\n",
    "    y_start.append(start_pos)\n",
    "    y_end.append(end_pos)\n",
    "#     print(y_start, y_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "X_pass = make_data(data['X_train'][:8000])\n",
    "# y_pass = data['y_train'][:400]\n",
    "y_pass_start = y_start[:8000]\n",
    "y_pass_end = y_end[:8000]\n",
    "print(len(X_pass))\n",
    "print(len(y_pass_start))\n",
    "print(len(y_pass_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ModelV1, self).__init__()\n",
    "        \n",
    "        self.input_size = config.get(\"input_size\", MAX_CONTEXT_LEN+MAX_QUES_LEN)\n",
    "        self.hidden_size = config.get(\"hidden_size\", 128)\n",
    "        self.output_size = config.get(\"output_size\", MAX_CONTEXT_LEN)\n",
    "        self.n_layers = config.get(\"n_layers\", 1)\n",
    "        self.vocab_size = config.get(\"vocab\", VOCAB_SIZE)\n",
    "        self.emb_dim = config.get(\"embedding_dim\", DIM)\n",
    "        self.bidir = config.get(\"Bidirectional\", True)\n",
    "        self.dirs = int(self.bidir)+1\n",
    "        self.lr = config.get(\"learning_rate\", 1e-3)\n",
    "        self.batch_size = config.get(\"batch_size\", 1)\n",
    "        self.epochs = config.get(\"epochs\", 5)\n",
    "        self.opt = config.get(\"opt\", \"SGD\")\n",
    "        \n",
    "        if self.opt == 'Adam':\n",
    "            self.opt = optim.Adam\n",
    "        else:\n",
    "            self.opt = optim.SGD\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.vocab_size, self.emb_dim)\n",
    "        self.lstm = nn.LSTM(self.emb_dim, self.hidden_size, self.n_layers, bidirectional=self.bidir)\n",
    "        self.decoder_start = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.decoder_end = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        weight_scale = 0.01\n",
    "        self.encoder.weight.data = glove.vectors\n",
    "        self.decoder_start.bias.data.fill_(0)\n",
    "        self.decoder_start.weight.data.uniform_(-weight_scale, weight_scale)\n",
    "        self.decoder_end.bias.data.fill_(0)\n",
    "        self.decoder_end.weight.data.uniform_(-weight_scale, weight_scale)\n",
    "\n",
    "    def init_hidden(self, bs=None):\n",
    "        if bs is None:\n",
    "            bs = self.batch_size\n",
    "        weight = next(self.parameters()).data\n",
    "        return var(weight.new(self.n_layers*self.dirs, bs, self.hidden_size).zero_())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if len(inputs)==1:\n",
    "            inputs = var(torch.LongTensor(inputs[0]))\n",
    "        else:\n",
    "            inputs = var(torch.LongTensor(inputs))\n",
    "#         print(inputs.size())\n",
    "        embeds = self.encoder(inputs).permute(1,0,2)# get glove repr\n",
    "#         print(\"embeds:\", embeds.size())\n",
    "        seq_len = embeds.size()[0]\n",
    "        lstm_op, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        # print(\"lstm op:\", lstm_op.size()) # (seq_len, bs, hidden_size*(dirs=2 for bi))\n",
    "        lstm_op = lstm_op.permute(1, 0, 2) # (seq_len, bs, hdim)->(bs, seq_len, hdim)\n",
    "#         print(lstm_op)\n",
    "        \n",
    "        end_pred = lstm_op[:, -1, :self.hidden_size] # forward direction\n",
    "        start_pred = lstm_op[:, -1, self.hidden_size:] # reverse direction\n",
    "        \n",
    "        # print(\"lstm start, end preds:\", start_pred.size(), end_pred.size())\n",
    "        out_start = F.log_softmax(self.decoder_start(start_pred), dim=-1)\n",
    "        out_end = F.log_softmax(self.decoder_end(end_pred), dim=-1)\n",
    "        # print(\"outs:\", out_start.size(), out_end.size())\n",
    "        out = torch.cat((out_start, out_end), 1)\n",
    "#         print(\"out:\", out.size())\n",
    "        return out\n",
    "    \n",
    "    def fit(self, X, y_s, y_e):\n",
    "        opt = self.opt(self.parameters(), self.lr)\n",
    "        losses = [] # epoch loss\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"epoch:\", epoch)\n",
    "            bs = self.batch_size\n",
    "#             print(bs)\n",
    "            bloss = 0.0 # batch loss\n",
    "#             loss_epoch = []\n",
    "#             print(len(y_s))\n",
    "            for i in range(0, len(y_s)-bs+1, bs):\n",
    "#                 print(i)\n",
    "#             for (x_data, y_data_s, y_data_e) in zip(X, y_s, y_e):\n",
    "                #print(\"batch:\", bindex)\n",
    "                h, c = self.init_hidden(), self.init_hidden()\n",
    "                self.hidden = (h, c)\n",
    "                # print(h.size(), c.size())\n",
    "                opt.zero_grad()\n",
    "#                 Xb = X[i:i+bs]\n",
    "#                 Xb = torch.LongTensor(Xb)\n",
    "#                 # print(\"Xb:\", Xb.size())\n",
    "#                 yb = var(torch.LongTensor(y[i:i+bs]))\n",
    "#                 # print(\"yb:\", yb.size())\n",
    "#                 pred = self.forward(Xb) #prediction on batch features\n",
    "                \n",
    "                x = X[i:i+bs]\n",
    "#                 print(x)\n",
    "#                 y = autograd.Variable(torch.LongTensor([y_data_s, y_data_e]), requires_grad=False)\n",
    "    #             Xb = X\n",
    "    #             yb = var(torch.LongTensor(y[i:i+bs]))\n",
    "                pred = self.forward(x) #prediction on batch features\n",
    "#                 print(pred)\n",
    "#                 print(autograd.Variable(torch.LongTensor(y_s[i:i+bs])))\n",
    "                y_s_temp = torch.LongTensor(y_s[i:i+bs])\n",
    "                y_e_temp = torch.LongTensor(y_e[i:i+bs])\n",
    "#                 print(y_s_temp.size())\n",
    "#                 print(y_s_temp.size())\n",
    "#                 print(pred.size())\n",
    "#                 print(y_data_s)\n",
    "            \n",
    "#                 loss= criterion(y_predicted, y)\n",
    "                loss = F.nll_loss(pred[:, :self.output_size], autograd.Variable(y_s_temp)) \\\n",
    "                     + F.nll_loss(pred[:, self.output_size:], autograd.Variable(y_e_temp)) \n",
    "#                 loss_epoch.append(loss.data[0])\n",
    "                bloss += loss.data[0]/bs\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            losses.append(bloss)\n",
    "            print(losses[-1], end=', change: ')\n",
    "            if len(losses)>1:\n",
    "                diff = losses[-2]-losses[-1]\n",
    "                rel_diff = diff/losses[-2]\n",
    "                print(\"%s\"%rel_diff, \"%\")\n",
    "            else:\n",
    "                print(\"00.0%\")\n",
    "        return losses\n",
    "\n",
    "    def predict(self, X, bs=None):\n",
    "        self.hidden = (self.init_hidden(bs), self.init_hidden(bs))\n",
    "        result = self.forward(X)\n",
    "        return self.get_span_indices(result)\n",
    "    \n",
    "    def get_span_indices(self, preds):\n",
    "        s_pred = preds[:, :self.output_size]\n",
    "        e_pred = preds[:, self.output_size:]\n",
    "        _,  s_index = torch.max(s_pred, -1)\n",
    "        _,  e_index = torch.max(e_pred, -1)\n",
    "        return torch.cat((s_index.unsqueeze(1), e_index.unsqueeze(1)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\"learning_rate\": 0.5, \n",
    "        \"epochs\": 20,\n",
    "       \"batch_size\": 50}\n",
    "model = ModelV1(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "38.23764572143555, change: 00.0%\n",
      "epoch: 1\n",
      "34.134663753509514, change: 0.10730215970451218 %\n",
      "epoch: 2\n",
      "33.62588384628299, change: 0.014905080386919468 %\n",
      "epoch: 3\n",
      "33.42245462417603, change: 0.006049780670061082 %\n",
      "epoch: 4\n",
      "33.28580827713014, change: 0.004088459348136774 %\n",
      "epoch: 5\n",
      "33.16873907089234, change: 0.00351709068510826 %\n",
      "epoch: 6\n",
      "33.053320121765154, change: 0.0034797508847261758 %\n",
      "epoch: 7\n",
      "32.92940980911255, change: 0.0037488007920575407 %\n",
      "epoch: 8\n",
      "32.793599472045905, change: 0.004124287008298016 %\n",
      "epoch: 9\n",
      "32.64163034439087, change: 0.00463410940249418 %\n",
      "epoch: 10\n"
     ]
    }
   ],
   "source": [
    "res = model.fit(X_pass, y_pass_start, y_pass_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(data['X_val'][:200], data['y_val'][:200]):\n",
    "    c = x[0]\n",
    "    a = x[2]\n",
    "    x = make_data([x])\n",
    "#     print(x)\n",
    "    temp_c = c.split()\n",
    "    temp_c = ['PAD']*(MAX_CONTEXT_LEN-len(temp_c))+temp_c\n",
    "#     con_new = ' '.join(temp_c)\n",
    "#     print(con_new)\n",
    "    res = model.predict([x], bs=1).data.tolist()[0]\n",
    "    print(\"Predicted span:\", res)\n",
    "    if res[0]>res[1]:\n",
    "        res[0], res[1] = res[1], res[0]\n",
    "        print(\"switched to:\", res)\n",
    "    print(\"Predicted Answer:\", temp_c[res[0]:res[1]])\n",
    "    print(\"Actual:\", a)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
