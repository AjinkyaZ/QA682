{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import json\n",
    "import _pickle as pkl\n",
    "from time import time\n",
    "from random import shuffle, seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400004, 50])\n"
     ]
    }
   ],
   "source": [
    "glove = setup_glove()\n",
    "print(glove.vectors.size())\n",
    "VOCAB_SIZE = glove.vectors.size()[0]\n",
    "with open('../data/data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 56ce602faab44d1400b88713\n",
      "Context: A solar chimney (or thermal chimney, in this context) is a passive solar ventilation system composed of a vertical shaft connecting the interior and exterior of a building. As the chimney warms, the air inside is heated causing an updraft that pulls air through the building. Performance can be improved by using glazing and thermal mass materials in a way that mimics greenhouses.\n",
      "Question: What kind of system is a solar chimney?\n",
      "Answer Span: [59, 84]\n",
      "Answer: passive solar ventilation\n",
      "[(547, 549)]\n",
      "passive solar ventilation\n",
      "===========\n",
      "512 512 32 32\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "example_X = (data['X_train'][idx])\n",
    "example_y = (data['y_train'][idx])\n",
    "print(\"ID:\", example_X[0])\n",
    "print(\"Context:\", example_X[1])\n",
    "print(\"Question:\", example_X[2])\n",
    "print(\"Answer Span:\", example_y)\n",
    "print(\"Answer:\", example_X[3])\n",
    "\n",
    "_, p, X, y = make_data([example_X], [example_y], 1, glove)\n",
    "print(y)\n",
    "print(get_answer_span(y[0], p[0], example_X[1]))\n",
    "print(\"===========\")\n",
    "\n",
    "seed(1)\n",
    "zipped_data = list(zip(data['X_train'], data['y_train']))\n",
    "# shuffle(zipped_data)\n",
    "data['X_train'], data['y_train'] = list(zip(*zipped_data))\n",
    "\n",
    "num_ex_train = 512\n",
    "num_ex_val = 32\n",
    "\n",
    "idxs_train, padlens_train, X_train, y_train = make_data(data['X_train'], data['y_train'], num_ex_train, glove)\n",
    "idxs_val, padlens_val, X_val, y_val = make_data(data['X_val'], data['y_val'], num_ex_val, glove)\n",
    "print(len(X_train), len(y_train), len(X_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelV2(\n",
      "  (encoder_c): Embedding(400004, 50)\n",
      "  (encoder_q): Embedding(400004, 50)\n",
      "  (gru_c): GRU(50, 32)\n",
      "  (gru_q): GRU(50, 32)\n",
      "  (lin_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (gru_coatt): GRU(96, 128, bidirectional=True)\n",
      "  (gru_bmod): GRU(256, 32)\n",
      "  (ans_ptr_1): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (ans_ptr_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (ans_ptr_3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (decoder_start): Linear(in_features=128, out_features=600, bias=True)\n",
      "  (decoder_end): Linear(in_features=128, out_features=600, bias=True)\n",
      ")\n",
      "ModelV2_D512_B32_E5_H32_LR0.01_OAdamax\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "conf = {\"vocab\": glove.vectors,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"epochs\": 5,\n",
    "        \"hidden_size\": 32,\n",
    "        \"batch_size\": 32,\n",
    "        \"opt\": \"Adamax\",\n",
    "        \"n_layers\": 1}\n",
    "\n",
    "model = ModelV2(conf)\n",
    "print(model)\n",
    "model_name = \"%s_D%s_B%s_E%s_H%s_LR%s_O%s\"%(type(model).__name__, num_ex_train, model.batch_size, model.epochs, model.hidden_size, model.lr, conf[\"opt\"])\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tic = time()\n",
    "v_preds, losses, vlosses = model.fit((X_train, y_train), (X_val, y_val))\n",
    "toc = time()\n",
    "print(\"took\", toc-tic, \"seconds\")\n",
    "torch.save(model, '../evaluation/models/%s'%model_name)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(len(losses))), losses, label='train')\n",
    "plt.plot(list(range(len(vlosses))), vlosses, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelV2(\n",
      "  (encoder_c): Embedding(400004, 50)\n",
      "  (encoder_q): Embedding(400004, 50)\n",
      "  (gru_c): GRU(50, 32)\n",
      "  (gru_q): GRU(50, 32)\n",
      "  (lin_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (gru_coatt): GRU(96, 128, bidirectional=True)\n",
      "  (gru_bmod): GRU(256, 32)\n",
      "  (ans_ptr_1): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (ans_ptr_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (ans_ptr_3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (decoder_start): Linear(in_features=128, out_features=600, bias=True)\n",
      "  (decoder_end): Linear(in_features=128, out_features=600, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model = torch.load('../evaluation/models/%s'%model_name)\n",
    "model = torch.load('../evaluation/models/ModelV2_D512_B32_E5_H32_LR0.01_OAdamax')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size: 128\n",
      "batch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:01,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:02,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "num_test = 128\n",
    "idxs_test, padlens_test, X_test, y_test = make_data(data['X_test'], data['y_test'], num_test, glove)\n",
    "\n",
    "dev_results = {}\n",
    "\n",
    "def switch_idxs(pred):\n",
    "    if pred[0]>pred[1]:\n",
    "        pred[0], pred[1] = pred[1], pred[0]\n",
    "    return pred\n",
    "\n",
    "bs = 32\n",
    "print(\"Test data size:\", num_test)\n",
    "for bindex,  i in tqdm(enumerate(range(0, len(y_test)-bs+1, bs))):\n",
    "    print(\"batch:\", bindex)\n",
    "    # model.init_params(bs)\n",
    "    Xb = torch.LongTensor(X_test[i:i+bs])\n",
    "    yb = var(torch.LongTensor(y_test[i:i+bs]))\n",
    "    \n",
    "    pred = model.predict(Xb).data.tolist()\n",
    "    pred = list(map(switch_idxs, pred))\n",
    "    qids = [data['X_test'][j][0] for j in idxs_test[i:i+bs]]\n",
    "    test_paras = [data['X_test'][j][1] for j in idxs_test[i:i+bs]]\n",
    "    pads = padlens_test[i:i+bs]\n",
    "    answers = list(map(get_answer_span, pred, pads, test_paras))\n",
    "    batch_results = list(zip(qids, answers))\n",
    "    # print(len(dict(batch_results)))\n",
    "    dev_results.update(dict(batch_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 43\n"
     ]
    }
   ],
   "source": [
    "num_processed = len(dev_results)\n",
    "print(\"processed:\", num_processed)\n",
    "dev_results['version'] = '1.1'\n",
    "fname = 'run_%s_test%s.json'%(model_name, num_processed)\n",
    "with open('../data/%s'%fname, 'w') as f:\n",
    "    json.dump(dev_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
