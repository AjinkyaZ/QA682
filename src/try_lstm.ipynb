{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import json\n",
    "import _pickle as pkl\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400004, 50])\n"
     ]
    }
   ],
   "source": [
    "glove = setup_glove()\n",
    "print(glove.vectors.size())\n",
    "VOCAB_SIZE = glove.vectors.size()[0]\n",
    "with open('../data/data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 56ce602faab44d1400b88713\n",
      "Context: A solar chimney (or thermal chimney, in this context) is a passive solar ventilation system composed of a vertical shaft connecting the interior and exterior of a building. As the chimney warms, the air inside is heated causing an updraft that pulls air through the building. Performance can be improved by using glazing and thermal mass materials in a way that mimics greenhouses.\n",
      "Question: What kind of system is a solar chimney?\n",
      "Answer Span: [59, 84]\n",
      "Answer: passive solar ventilation\n",
      "[(11, 13)]\n",
      "passive solar ventilation\n",
      "Skipped: 2\n",
      "128 128 32 32\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "example_X = (data['X_train'][idx])\n",
    "example_y = (data['y_train'][idx])\n",
    "print(\"ID:\", example_X[0])\n",
    "print(\"Context:\", example_X[1])\n",
    "print(\"Question:\", example_X[2])\n",
    "print(\"Answer Span:\", example_y)\n",
    "print(\"Answer:\", example_X[3])\n",
    "\n",
    "X, y = make_data([example_X], [example_y], 1)\n",
    "pprint(y)\n",
    "print(get_answer_span(y[0], example_X[1]))\n",
    "num_ex_train = 128\n",
    "num_ex_val = 32\n",
    "X_train, y_train = make_data(data['X_train'], data['y_train'], num_ex_train)\n",
    "X_val, y_val = make_data(data['X_val'], data['y_val'], num_ex_val)\n",
    "print(len(X_train), len(y_train), len(X_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelV2(\n",
      "  (encoder_c): Embedding(400004, 50)\n",
      "  (encoder_q): Embedding(400004, 50)\n",
      "  (gru_c): GRU(50, 32)\n",
      "  (gru_q): GRU(50, 32)\n",
      "  (lin_q): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (gru_coatt): GRU(96, 128, bidirectional=True)\n",
      "  (gru_bmod): GRU(256, 32)\n",
      "  (ans_ptr_1): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (ans_ptr_2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (ans_ptr_3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (decoder_start): Linear(in_features=128, out_features=600, bias=True)\n",
      "  (decoder_end): Linear(in_features=128, out_features=600, bias=True)\n",
      ")\n",
      "ModelV2_D128_B32_E10_H32_LR0.1\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "conf = {\"vocab\": glove.vectors,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"epochs\": 10,\n",
    "        \"hidden_size\": 32,\n",
    "        \"batch_size\": 32,\n",
    "        \"opt\": \"Adam\",\n",
    "        \"n_layers\": 1}\n",
    "model = ModelV2(conf)\n",
    "print(model)\n",
    "model_name = \"%s_D%s_B%s_E%s_H%s_LR%s\"%(type(model).__name__, num_ex_train, model.batch_size, model.epochs, model.hidden_size, model.lr)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n",
      "batches: 4.0\n",
      "epoch: 0\n",
      "0 : 12.793858528137207\n",
      "1 : 12.793899536132812\n",
      "2 : 12.793862342834473\n",
      "3 : 12.793856620788574\n",
      "\n",
      "loss (epoch): 0.3998084142804146, change: 00.0%\n",
      "validation loss: 0.39980801939964294\n",
      "epoch: 1\n",
      "0 : 12.793856620788574\n",
      "1 : 12.793856620788574\n",
      "2 : 12.793856620788574\n",
      "3 : 12.793856620788574\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0ca5fe3a2fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mv_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../evaluation/models/%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/squad682/src/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, val_data)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mbloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "v_preds, losses, vlosses = model.fit((X_train, y_train), (X_val, y_val))\n",
    "toc = time()\n",
    "print(\"took\", toc-tic, \"seconds\")\n",
    "torch.save(model, '../evaluation/models/%s'%model_name)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.plot(list(range(len(vlosses))), vlosses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../evaluation/models/%s'%model_name)\n",
    "print(model)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ex_test = 100\n",
    "X_test_data, y_test_data = make_data(data['X_test'], data['y_test'], num_ex_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dev_results = {}\n",
    "seen_contexts = set()\n",
    "seen_questions = set()\n",
    "from hashlib import sha1\n",
    "\n",
    "model.init_params(1)\n",
    "for i, (x, y) in enumerate(zip(X_test_data, y_test_data)):\n",
    "    qid = data['X_test'][i][0]\n",
    "    if qid not in seen_questions:\n",
    "        seen_questions.add(qid)\n",
    "    else:\n",
    "        continue\n",
    "    c = data['X_test'][i][1]\n",
    "    context_h = sha1(c.encode('utf-8')).hexdigest()\n",
    "    if context_h not in seen_contexts:\n",
    "        print(c)\n",
    "        print(\"-\"*30)\n",
    "        seen_contexts.add(context_h)\n",
    "    q = data['X_test'][i][2]\n",
    "    print(\"QUESTION: \", q)\n",
    "    a = data['X_test'][i][3]\n",
    "    print(\"ANSWER: \", a)\n",
    "    res = model.predict([x], bs=1).data.tolist()[0]\n",
    "    if res[0]>res[1]:\n",
    "        res[0], res[1] = res[1], res[0]\n",
    "    ans = get_answer_span(res, c)\n",
    "    print(\"PRED_SPAN: \", res)\n",
    "    print(\"PREDICTED: \", ans)\n",
    "    dev_results[qid] = ans\n",
    "    print(\"=\"*50)\n",
    "with open('../data/run_%sdata_%sepochs.json'%(num_ex, model.epochs), 'w') as f:\n",
    "    json.dump(dev_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
