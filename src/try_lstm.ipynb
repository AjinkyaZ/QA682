{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable as var\n",
    "from torch.nn import functional as F\n",
    "import torchtext.vocab as vocab\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import json\n",
    "import _pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def clean(token):\n",
    "    cleaned_token = token.strip(\".,?!-:;'()[]\\\"`\")\n",
    "    if cleaned_token[-2:] == \"'s\":\n",
    "        cleaned_token = cleaned_token[:-2]\n",
    "    if cleaned_token[-2:] == \"'t\":\n",
    "        cleaned_token = cleaned_token[:-2]+'t'\n",
    "    return cleaned_token\n",
    "\n",
    "def vectorize(input_txt, max_len):\n",
    "    input_seq = [clean(w) for w in input_txt.split(\" \") if len(clean(w).strip())]\n",
    "    glove_vec = []\n",
    "    for w in input_seq:\n",
    "        try:\n",
    "            glove_vec.append(glove.stoi[w])\n",
    "        except:\n",
    "            glove_vec.append(400001) # <unk> token\n",
    "    if len(glove_vec)<max_len:\n",
    "        padding_zeros = [400000]*(max_len-len(glove_vec)) # <pad> token\n",
    "        glove_vec = padding_zeros + glove_vec\n",
    "    return glove_vec[:max_len]\n",
    "    \n",
    "def make_data(raw_X):\n",
    "    X = []\n",
    "    y = []\n",
    "    for (c, q, a) in raw_X:\n",
    "        context_rep = vectorize(c.lower(), 600)\n",
    "        ques_rep = vectorize(q.lower(), 100)\n",
    "        X.append(context_rep+ques_rep) #only context for now\n",
    "    return X\n",
    "\n",
    "DIM=50\n",
    "glove = vocab.GloVe(name='6B', dim=DIM)\n",
    "\n",
    "glove.stoi['<pad>'] = len(glove.stoi)+1\n",
    "glove.vectors = torch.cat((glove.vectors, torch.zeros(1, DIM)))\n",
    "glove.stoi['<unk>'] = len(glove.stoi)+1 # add token->index for unknown/oov\n",
    "glove.vectors = torch.cat((glove.vectors, torch.ones(1, DIM)*-1)) # add index->vec for unknown/oov\n",
    "\n",
    "print(glove.vectors.size())\n",
    "VOCAB_SIZE = glove.vectors.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 5\n",
    "example_X = (data['X_train'][idx])\n",
    "example_y = (data['y_train'][idx])\n",
    "print(\"Context:\", example_X[0])\n",
    "print(\"Question:\", example_X[1])\n",
    "print(\"Answer Span:\", example_y)\n",
    "print(\"Answer:\", example_X[2])\n",
    "X = make_data([example_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ex = 4000\n",
    "X_pass = make_data(data['X_train'][:num_ex])\n",
    "y_pass = data['y_train'][:num_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ModelV1, self).__init__()\n",
    "        \n",
    "        self.input_size = config.get(\"input_size\", 700)\n",
    "        self.hidden_size = config.get(\"hidden_size\", 128)\n",
    "        self.output_size = config.get(\"output_size\", 5000)\n",
    "        self.n_layers = config.get(\"n_layers\", 1)\n",
    "        self.vocab_size = config.get(\"vocab\", VOCAB_SIZE)\n",
    "        self.emb_dim = config.get(\"embedding_dim\", DIM)\n",
    "        self.bidir = config.get(\"Bidirectional\", True)\n",
    "        self.dirs = int(self.bidir)+1\n",
    "        self.lr = config.get(\"learning_rate\", 1e-3)\n",
    "        self.batch_size = config.get(\"batch_size\", 1)\n",
    "        self.epochs = config.get(\"epochs\", 5)\n",
    "        self.opt = config.get(\"opt\", \"SGD\")\n",
    "        \n",
    "        if self.opt == 'Adam':\n",
    "            self.opt = optim.Adam\n",
    "        else:\n",
    "            self.opt = optim.SGD\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.vocab_size, self.emb_dim)\n",
    "        self.lstm = nn.LSTM(self.emb_dim, self.hidden_size, self.n_layers, bidirectional=self.bidir)\n",
    "        self.decoder_start = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.decoder_end = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        weight_scale = 0.01\n",
    "        self.encoder.weight.data = glove.vectors\n",
    "        self.decoder_start.bias.data.fill_(0)\n",
    "        self.decoder_start.weight.data.uniform_(-weight_scale, weight_scale)\n",
    "        self.decoder_end.bias.data.fill_(0)\n",
    "        self.decoder_end.weight.data.uniform_(-weight_scale, weight_scale)\n",
    "\n",
    "    def init_hidden(self, bs=None):\n",
    "        if bs is None:\n",
    "            bs = self.batch_size\n",
    "        weight = next(self.parameters()).data\n",
    "        return var(weight.new(self.n_layers*self.dirs, bs, self.hidden_size).zero_())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if len(inputs)==1:\n",
    "            inputs = var(torch.LongTensor(inputs[0]))\n",
    "        else:\n",
    "            inputs = var(torch.LongTensor(inputs))\n",
    "        # print(inputs.size())\n",
    "        embeds = self.encoder(inputs).permute(1, 0, 2) # get glove repr\n",
    "        # print(\"embeds:\", embeds.size())\n",
    "        seq_len = embeds.size()[0]\n",
    "        lstm_op, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        # print(\"lstm op:\", lstm_op.size()) # (seq_len, bs, hidden_size*(dirs=2 for bi))\n",
    "        lstm_op = lstm_op.permute(1, 0, 2) # (seq_len, bs, hdim)->(bs, seq_len, hdim)\n",
    "        \n",
    "        end_pred = lstm_op[:, -1, :self.hidden_size] # forward direction\n",
    "        start_pred = lstm_op[:, -1, self.hidden_size:] # reverse direction\n",
    "        \n",
    "        # print(\"lstm start, end preds:\", start_pred.size(), end_pred.size())\n",
    "        out_start = F.log_softmax(self.decoder_start(start_pred), dim=-1)\n",
    "        out_end = F.log_softmax(self.decoder_end(end_pred), dim=-1)\n",
    "        # print(\"outs:\", out_start.size(), out_end.size())\n",
    "        out = torch.cat((out_start, out_end), 1)\n",
    "        # print(\"out:\", out.size())\n",
    "        return out\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        opt = self.opt(self.parameters(), self.lr)\n",
    "        losses = [] # epoch loss\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"epoch:\", epoch)\n",
    "            bs = self.batch_size\n",
    "            bloss = 0.0 # batch loss\n",
    "            for bindex,  i in tqdm(enumerate(range(0, len(y)-bs+1, bs))):\n",
    "                #print(\"batch:\", bindex)\n",
    "                h, c = self.init_hidden(), self.init_hidden()\n",
    "                self.hidden = (h, c)\n",
    "                # print(h.size(), c.size())\n",
    "                opt.zero_grad()\n",
    "                Xb = X[i:i+bs]\n",
    "                Xb = torch.LongTensor(Xb)\n",
    "                # print(\"Xb:\", Xb.size())\n",
    "                yb = var(torch.LongTensor(y[i:i+bs]))\n",
    "                # print(\"yb:\", yb.size())\n",
    "                pred = self.forward(Xb) #prediction on batch features\n",
    "            \n",
    "                loss = F.nll_loss(pred[:, :self.output_size], yb[:, 0]) \\\n",
    "                     + F.nll_loss(pred[:, self.output_size:], yb[:, 1]) \n",
    "                bloss += loss.data[0]/bs\n",
    "                # print(bloss)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            losses.append(bloss)\n",
    "            print(\"loss:\", losses[-1], end=', change: ')\n",
    "            if len(losses)>1:\n",
    "                diff = losses[-2]-losses[-1]\n",
    "                rel_diff = diff/losses[-2]\n",
    "                print(\"%s\"%rel_diff, \"%\")\n",
    "            else:\n",
    "                print(\"00.0%\")\n",
    "        return losses\n",
    "\n",
    "    def predict(self, X, bs=None):\n",
    "        self.hidden = (self.init_hidden(bs), self.init_hidden(bs))\n",
    "        result = self.forward(X)\n",
    "        return self.get_span_indices(result)\n",
    "    \n",
    "    def get_span_indices(self, preds):\n",
    "        s_pred = preds[:, :self.output_size]\n",
    "        e_pred = preds[:, self.output_size:]\n",
    "        _,  s_index = torch.max(s_pred, -1)\n",
    "        _,  e_index = torch.max(e_pred, -1)\n",
    "        return torch.cat((s_index.unsqueeze(1), e_index.unsqueeze(1)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\"learning_rate\": 0.4, \n",
    "        \"epochs\": 10,\n",
    "        \"hidden_size\": 128,\n",
    "       \"batch_size\": 40,\n",
    "       \"opt\": \"Adam\",\n",
    "        }\n",
    "model = ModelV1(conf)\n",
    "print(model, model.lr, model.hidden_size, model.batch_size, model.opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = model.fit(X_pass, y_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x, y in zip(data['X_val'][:20], data['y_val'][:20]):\n",
    "    c = x[0]\n",
    "    a = x[2]\n",
    "    x = make_data([x])\n",
    "    res = model.predict([x], bs=1).data.tolist()[0]\n",
    "    print(\"Predicted span:\", res)\n",
    "    if res[0]>res[1]:\n",
    "        res[0], res[1] = res[1], res[0]\n",
    "        print(\"switched to:\", res)\n",
    "    print(\"Predicted Answer:\", c[res[0]:res[1]])\n",
    "    print(\"Actual:\", a)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(len(res))), res)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
