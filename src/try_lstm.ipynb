{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable as var\n",
    "from torch.nn import functional as F\n",
    "import torchtext.vocab as vocab\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import json\n",
    "import _pickle as pkl\n",
    "import os\n",
    "from multiprocessing import Pool, Manager\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400002, 50])\n"
     ]
    }
   ],
   "source": [
    "with open('../data/data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def clean(token):\n",
    "    cleaned_token = token.strip(\".,?!-:;'()[]\\\"`\")\n",
    "    if cleaned_token[-2:] == \"'s\":\n",
    "        cleaned_token = cleaned_token[:-2]\n",
    "    if cleaned_token[-2:] == \"'t\":\n",
    "        cleaned_token = cleaned_token[:-2]+'t'\n",
    "    return cleaned_token\n",
    "\n",
    "def tokenize(input_txt):\n",
    "    return [w for w in input_txt.split(\" \") if len(clean(w).strip())]\n",
    "        \n",
    "def token_idx_map(input_txt):\n",
    "    input_seq = tokenize(input_txt)\n",
    "    tok_idx_map = {\"start\": {}, \"end\": {}}\n",
    "    curr_word = \"\"\n",
    "    curr_word_idx = 0\n",
    "\n",
    "    for i, c in enumerate(input_txt):\n",
    "        if c != \" \":\n",
    "            curr_word += c\n",
    "            try:\n",
    "                input_tok = input_seq[curr_word_idx]\n",
    "            except:\n",
    "                input_tok = input_seq[curr_word_idx-1] #trailing spaces can cause this exception\n",
    "            if curr_word == input_tok:\n",
    "                s = i - len(curr_word) + 1\n",
    "                e = i + 1 # since span is from [start, end)\n",
    "                tok_idx_map[\"start\"][s] = [curr_word_idx, curr_word]  # record what token starts here\n",
    "                tok_idx_map[\"end\"][e] = [curr_word_idx, curr_word] # record what token ends here\n",
    "                curr_word = \"\"\n",
    "                curr_word_idx += 1\n",
    "    assert len(tok_idx_map[\"start\"]) == len(tok_idx_map[\"end\"])\n",
    "    return tok_idx_map\n",
    "\n",
    "def reverse_mapping(tok_idx_map):\n",
    "    new_map = {}\n",
    "    for k, v in tok_idx_map[\"start\"].items():\n",
    "        new_map[v[0]] = [v[1], k] # word, start\n",
    "    for k, v in tok_idx_map[\"end\"].items():\n",
    "        assert k in new_map\n",
    "        new_map[v[0]].append(k) # end\n",
    "    return new_map\n",
    "\n",
    "def get_answer_span(tok_idxs, input_txt):\n",
    "    input_seq = tokenize(input_txt)\n",
    "    s, e = tok_idxs\n",
    "    return \" \".join(input_seq[s:e+1])\n",
    "\n",
    "def vectorize(input_seq, max_len):\n",
    "    glove_vec = []\n",
    "    for w in input_seq:\n",
    "        try:\n",
    "            glove_vec.append(glove.stoi[clean(w)])\n",
    "        except:\n",
    "            glove_vec.append(400001) # <unk> token\n",
    "    if len(glove_vec)<max_len:\n",
    "        padding_zeros = [400000]*(max_len-len(glove_vec)) # <pad> token\n",
    "        glove_vec = padding_zeros + glove_vec\n",
    "    return glove_vec[:max_len]\n",
    "    \n",
    "def make_data(raw_X, raw_y):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, ((qid, c, q, a), (s, e)) in enumerate(zip(raw_X, raw_y)):\n",
    "        c_tokens = tokenize(c.lower())\n",
    "        try:\n",
    "            tok_idx_map = token_idx_map(c)\n",
    "        except:\n",
    "            print(c, q, a)\n",
    "        #pprint(tok_idx_map)\n",
    "        #pprint(reverse_mapping(tok_idx_map))\n",
    "        try:\n",
    "            start_tok_idx, start_w = tok_idx_map[\"start\"][s]\n",
    "        except:\n",
    "            for i in range(s, e):\n",
    "                if i in tok_idx_map[\"start\"]: # get next tok\n",
    "                    start_tok_idx, start_w = tok_idx_map[\"start\"][i]\n",
    "                    break\n",
    "        try:\n",
    "            end_tok_idx, _ = tok_idx_map[\"end\"][e] #only idx, not token\n",
    "        except:\n",
    "            for i in range(e, s, -1):\n",
    "                if i in tok_idx_map[\"end\"]: # get prev tok\n",
    "                    end_tok_idx, end_w = tok_idx_map[\"end\"][i]\n",
    "                    break\n",
    "        context_rep = vectorize(c_tokens, 600)\n",
    "        q_tokens = tokenize(q.lower())\n",
    "        ques_rep = vectorize(q_tokens, 100)\n",
    "        X.append(context_rep+ques_rep)\n",
    "        y.append((start_tok_idx, end_tok_idx))\n",
    "    return X, y\n",
    "\n",
    "DIM=50\n",
    "glove = vocab.GloVe(name='6B', dim=DIM)\n",
    "\n",
    "glove.stoi['<pad>'] = len(glove.stoi)+1\n",
    "glove.vectors = torch.cat((glove.vectors, torch.zeros(1, DIM)))\n",
    "glove.stoi['<unk>'] = len(glove.stoi)+1 # add token->index for unknown/oov\n",
    "glove.vectors = torch.cat((glove.vectors, torch.ones(1, DIM)*-1)) # add index->vec for unknown/oov\n",
    "\n",
    "print(glove.vectors.size())\n",
    "VOCAB_SIZE = glove.vectors.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 56ce602faab44d1400b88713\n",
      "Context: A solar chimney (or thermal chimney, in this context) is a passive solar ventilation system composed of a vertical shaft connecting the interior and exterior of a building. As the chimney warms, the air inside is heated causing an updraft that pulls air through the building. Performance can be improved by using glazing and thermal mass materials in a way that mimics greenhouses.\n",
      "Question: What kind of system is a solar chimney?\n",
      "Answer Span: [59, 84]\n",
      "Answer: passive solar ventilation\n",
      "[(11, 13)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'passive solar ventilation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 5\n",
    "example_X = (data['X_train'][idx])\n",
    "example_y = (data['y_train'][idx])\n",
    "print(\"ID:\", example_X[0])\n",
    "print(\"Context:\", example_X[1])\n",
    "print(\"Question:\", example_X[2])\n",
    "print(\"Answer Span:\", example_y)\n",
    "print(\"Answer:\", example_X[3])\n",
    "X, y = make_data([example_X], [example_y])\n",
    "pprint(y)\n",
    "get_answer_span(y[0], example_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_ex = 1000\n",
    "X_pass, y_pass = make_data(data['X_train'][:num_ex], data['y_train'][:num_ex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ModelV1, self).__init__()\n",
    "        \n",
    "        self.input_size = config.get(\"input_size\", 700)\n",
    "        self.hidden_size = config.get(\"hidden_size\", 128)\n",
    "        self.output_size = config.get(\"output_size\", 600)\n",
    "        self.n_layers = config.get(\"n_layers\", 1)\n",
    "        self.vocab_size = config.get(\"vocab\", VOCAB_SIZE)\n",
    "        self.emb_dim = config.get(\"embedding_dim\", DIM)\n",
    "        self.bidir = config.get(\"Bidirectional\", True)\n",
    "        self.dirs = int(self.bidir)+1\n",
    "        self.lr = config.get(\"learning_rate\", 1e-3)\n",
    "        self.batch_size = config.get(\"batch_size\", 1)\n",
    "        self.epochs = config.get(\"epochs\", 5)\n",
    "        self.opt = config.get(\"opt\", \"SGD\")\n",
    "        self.print_every = config.get(\"print_every\", 10)\n",
    "        \n",
    "        if self.opt == 'Adam':\n",
    "            self.opt = optim.Adam\n",
    "        else:\n",
    "            self.opt = optim.SGD\n",
    "        \n",
    "        self.encoder = nn.Embedding(self.vocab_size, self.emb_dim)\n",
    "        self.lstm = nn.LSTM(self.emb_dim, self.hidden_size, self.n_layers, bidirectional=self.bidir)\n",
    "        self.decoder_start = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.decoder_end = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        weight_scale = 0.01\n",
    "        self.encoder.weight.data = glove.vectors\n",
    "        self.decoder_start.bias.data.fill_(0)\n",
    "        self.decoder_start.weight.data.uniform_(-weight_scale, weight_scale)\n",
    "        self.decoder_end.bias.data.fill_(0)\n",
    "        self.decoder_end.weight.data.uniform_(-weight_scale, weight_scale)\n",
    "\n",
    "    def init_hidden(self, bs=None):\n",
    "        if bs is None:\n",
    "            bs = self.batch_size\n",
    "        weight = next(self.parameters()).data\n",
    "        return var(weight.new(self.n_layers*self.dirs, bs, self.hidden_size).zero_())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        if len(inputs)==1:\n",
    "            inputs = var(torch.LongTensor(inputs[0]))\n",
    "        else:\n",
    "            inputs = var(torch.LongTensor(inputs))\n",
    "        if len(inputs.size())<2:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "        embeds = self.encoder(inputs).permute(1, 0, 2) # get glove repr\n",
    "        # print(\"embeds:\", embeds.size())\n",
    "        seq_len = embeds.size()[0]\n",
    "        lstm_op, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        # print(\"lstm op:\", lstm_op.size()) # (seq_len, bs, hidden_size*(dirs=2 for bi))\n",
    "        lstm_op = lstm_op.permute(1, 0, 2) # (seq_len, bs, hdim)->(bs, seq_len, hdim)\n",
    "        \n",
    "        end_pred = lstm_op[:, -1, :self.hidden_size] # forward direction\n",
    "        start_pred = lstm_op[:, -1, self.hidden_size:] # reverse direction\n",
    "        \n",
    "        # print(\"lstm start, end preds:\", start_pred.size(), end_pred.size())\n",
    "        out_start = F.log_softmax(self.decoder_start(start_pred), dim=-1)\n",
    "        out_end = F.log_softmax(self.decoder_end(end_pred), dim=-1)\n",
    "        # print(\"outs:\", out_start.size(), out_end.size())\n",
    "        out = torch.cat((out_start, out_end), 1)\n",
    "        # print(\"out:\", out.size())\n",
    "        return out\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        opt = self.opt(self.parameters(), self.lr)\n",
    "        losses = [] # epoch loss\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"epoch:\", epoch)\n",
    "            bs = self.batch_size\n",
    "            bloss = 0.0 # batch loss\n",
    "            for bindex,  i in enumerate(range(0, len(y)-bs+1, bs)):\n",
    "                #print(\"batch:\", bindex)                    \n",
    "                h, c = self.init_hidden(), self.init_hidden()\n",
    "                self.hidden = (h, c)\n",
    "                # print(h.size(), c.size())\n",
    "                opt.zero_grad()\n",
    "                Xb = X[i:i+bs]\n",
    "                Xb = torch.LongTensor(Xb)\n",
    "                # print(\"Xb:\", Xb.size())\n",
    "                yb = var(torch.LongTensor(y[i:i+bs]))\n",
    "                # print(\"yb:\", yb.size())\n",
    "                pred = self.forward(Xb) #prediction on batch features\n",
    "            \n",
    "                loss = F.nll_loss(pred[:, :self.output_size], yb[:, 0]) \\\n",
    "                     + F.nll_loss(pred[:, self.output_size:], yb[:, 1]) \n",
    "                if bindex*(epoch+1)%self.print_every==0:\n",
    "                    print(\"loss (batch):\", loss.data[0])\n",
    "                bloss += loss.data[0]/bs\n",
    "                # print(bloss)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            losses.append(bloss)\n",
    "            print(\"loss (epoch):\", losses[-1], end=', change: ')\n",
    "            if len(losses)>1:\n",
    "                diff = losses[-2]-losses[-1]\n",
    "                rel_diff = diff/losses[-2]\n",
    "                print(\"%s\"%rel_diff, \"%\")\n",
    "            else:\n",
    "                print(\"00.0%\")\n",
    "        return losses\n",
    "\n",
    "    def predict(self, X, bs=None):\n",
    "        # self.hidden = (self.init_hidden(bs), self.init_hidden(bs))\n",
    "        result = self.forward(X)\n",
    "        return self.get_span_indices(result)\n",
    "    \n",
    "    def get_span_indices(self, preds):\n",
    "        s_pred = preds[:, :self.output_size]\n",
    "        e_pred = preds[:, self.output_size:]\n",
    "        _,  s_index = torch.max(s_pred, -1)\n",
    "        _,  e_index = torch.max(e_pred, -1)\n",
    "        return torch.cat((s_index.unsqueeze(1), e_index.unsqueeze(1)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelV1(\n",
      "  (encoder): Embedding(400002, 50)\n",
      "  (lstm): LSTM(50, 64, bidirectional=True)\n",
      "  (decoder_start): Linear(in_features=64, out_features=600, bias=True)\n",
      "  (decoder_end): Linear(in_features=64, out_features=600, bias=True)\n",
      ") 0.4 64 50 <class 'torch.optim.adam.Adam'>\n",
      "BiLSTM_1000_5_64_1\n"
     ]
    }
   ],
   "source": [
    "conf = {\"learning_rate\": 0.4, \n",
    "        \"epochs\": 5,\n",
    "        \"hidden_size\": 64,\n",
    "       \"batch_size\": 50,\n",
    "       \"opt\": \"Adam\",\n",
    "        \"n_layers\": 1\n",
    "        }\n",
    "model = ModelV1(conf)\n",
    "print(model, model.lr, model.hidden_size, model.batch_size, model.opt)\n",
    "model_name = \"BiLSTM_%s_%s_%s_%s\"%(num_ex, model.epochs, model.hidden_size, model.n_layers)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "loss (batch): 12.792482376098633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-58b4d0455df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"took\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoc\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../evaluation/models/%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d0d50c5b13a3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mbloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# print(bloss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "res = model.fit(X_pass, y_pass)\n",
    "toc = time()\n",
    "print(\"took\", toc-tic, \"seconds\")\n",
    "torch.save(model, '../evaluation/models/%s'%model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../evaluation/models/%s'%model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data, y_test_data = make_data(data['X_test'][:100], data['y_test'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (2, 1, 64), got (2, 50, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8f8bccccfc2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(a)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(\"Predicted span:\", res)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#if res[0]>res[1]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d0d50c5b13a3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, bs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# self.hidden = (self.init_hidden(bs), self.init_hidden(bs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_span_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-d0d50c5b13a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# print(\"embeds:\", embeds.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mlstm_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;31m# print(\"lstm op:\", lstm_op.size()) # (seq_len, bs, hidden_size*(dirs=2 for bi))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlstm_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq_len, bs, hdim)->(bs, seq_len, hdim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 158\u001b[0;31m                               'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    159\u001b[0m             check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    160\u001b[0m                               'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (2, 1, 64), got (2, 50, 64)"
     ]
    }
   ],
   "source": [
    "dev_results = {}\n",
    "for i, (x, y) in enumerate(zip(X_test_data[:1000], y_test_data[:1000])):\n",
    "    qid = data['X_test'][i][0]\n",
    "    c = data['X_test'][i][1]\n",
    "    q = data['X_test'][i][2]\n",
    "    #print(c)\n",
    "    #print(q)\n",
    "    a = data['X_test'][i][3]\n",
    "    #print(a)\n",
    "    res = model.predict([x], bs=1).data.tolist()[0]\n",
    "    #print(\"Predicted span:\", res)\n",
    "    #if res[0]>res[1]:\n",
    "    #    res[0], res[1] = res[1], res[0]\n",
    "        #print(\"switched to:\", res)\n",
    "    #print(\"Predicted Answer:\", c[res[0]:res[1]])\n",
    "    #print(\"Actual:\", a)\n",
    "    print(res)\n",
    "    ans = get_answer_span(res, c)\n",
    "    #print(\"-\"*50)\n",
    "    #print(ans)\n",
    "    dev_results[qid] = ans\n",
    "    print(\"=\"*50)\n",
    "with open('../data/run_500data_5epochs.json', 'w') as f:\n",
    "    json.dump(dev_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(range(len(res))), res)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
